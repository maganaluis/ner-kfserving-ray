{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "https://blog.codecentric.de/en/2020/11/take-control-of-named-entity-recognition-with-you-own-keras-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_label(filename):\n",
    "    out = []\n",
    "    labels = []\n",
    "    words = []\n",
    "    unique = set()\n",
    "    with open(filename) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.lstrip().strip()\n",
    "            if line.startswith(\"-DOCSTART-\") or len(line) == 0:\n",
    "                if labels and words:\n",
    "                    out.append([\" \".join(words), \" \".join(labels)])\n",
    "                labels = []\n",
    "                words = []\n",
    "            else:\n",
    "                items = line.split(\" \")\n",
    "                words.append(items[0])\n",
    "                labels.append(items[-1])\n",
    "                unique.add(items[-1])\n",
    "        return out, unique\n",
    "\n",
    "def preprocess(samples, labels_to_index, embeddings_index):\n",
    "    X = np.zeros((len(samples), MAX_LEN, EMB_DIM), dtype=np.float32)\n",
    "    y = np.zeros((len(samples), MAX_LEN), dtype=np.uint8)\n",
    "    default = np.random.rand(EMB_DIM).astype('float32')\n",
    "    labels_out = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        sentence = sample[0].split()\n",
    "        labels = sample[1].split()\n",
    "        labels_out.append(labels)\n",
    "        for j, token in enumerate(sentence[:MAX_LEN]):\n",
    "            X[i, j] = embeddings_index.get(token, default)\n",
    "            y[i, j] = labels_to_index[labels[j]]\n",
    "    return X, y, labels_out\n",
    "\n",
    "def preprocessInference(samples, labels_to_index, embeddings_index):\n",
    "    X = np.zeros((len(samples), MAX_LEN, EMB_DIM), dtype=np.float32)\n",
    "    default = np.random.rand(EMB_DIM).astype('float32')\n",
    "    num_tokens = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        sentence = sample.split()\n",
    "        num_tokens.append(len(sentence))\n",
    "        for j, token in enumerate(sentence[:MAX_LEN]):\n",
    "            X[i, j] = embeddings_index.get(token, default)\n",
    "    return X, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, _= split_text_label(\"./eng.testa\")\n",
    "validation, _ = split_text_label(\"./eng.testb\")\n",
    "train, unique = split_text_label(\"./eng.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_index = {w:i for i, w in enumerate(sorted(list(unique)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOC': 0,\n",
       " 'B-MISC': 1,\n",
       " 'B-ORG': 2,\n",
       " 'I-LOC': 3,\n",
       " 'I-MISC': 4,\n",
       " 'I-ORG': 5,\n",
       " 'I-PER': 6,\n",
       " 'O': 7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"wiki-news-300d-1M.vec\"\n",
    "MAX_LEN = 124\n",
    "EMB_DIM = 300\n",
    "NUM_LABELS = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingsIndex():\n",
    "    out = {}\n",
    "    with open(EMBEDDING_FILE) as f:\n",
    "        for line in f.readlines():\n",
    "            data = line.split(\" \")\n",
    "            out[data[0]] = np.array(data[1:], dtype='float32')\n",
    "        return out\n",
    "\n",
    "embeddings_index = getEmbeddingsIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, _ = preprocess(train, labels_to_index, embeddings_index)\n",
    "X_test, y_test, test_labels = preprocess(test, labels_to_index, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from sklearn.metrics import classification_report\n",
    " \n",
    "def build_model(nr_filters=128):\n",
    "    input_shape = (MAX_LEN, EMB_DIM)\n",
    "    lstm = LSTM(nr_filters, return_sequences=True)\n",
    "    bi_lstm = Bidirectional(lstm, input_shape=input_shape)\n",
    "    tag_classifier = Dense(NUM_LABELS, activation='softmax')\n",
    "    sequence_labeller = TimeDistributed(tag_classifier)\n",
    "    return Sequential([bi_lstm, sequence_labeller])\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 7s 14ms/step - loss: 0.3874 - accuracy: 0.9570 - val_loss: 0.0265 - val_accuracy: 0.9929\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.0169 - val_accuracy: 0.9951\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0146 - val_accuracy: 0.9958\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0138 - val_accuracy: 0.9961\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0127 - val_accuracy: 0.9965\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 3s 10ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0120 - val_accuracy: 0.9966\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0117 - val_accuracy: 0.9968\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 3s 11ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0118 - val_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "def train(model, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics='accuracy')\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=0.4,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size)\n",
    "    return history.history\n",
    "\n",
    "history = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test):\n",
    "    y_probs = model.predict(X_test)\n",
    "    return np.argmax(y_probs, axis=-1)\n",
    "\n",
    "predictions = predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, y_test, test_labels, labels_to_index):\n",
    "    assert len(predictions) == len(y_test) == len(test_labels)\n",
    "    reverse_label_index = {v:k for k,v in labels_to_index.items()}\n",
    "    n = len(predictions)\n",
    "    y = []\n",
    "    y_hat = []\n",
    "    for i in range(n):\n",
    "        y_hat += predictions[i][:len(test_labels[i])].tolist()\n",
    "        y += y_test[i][:len(test_labels[i])].tolist()\n",
    "        \n",
    "    y_hat = list(map(lambda x: reverse_label_index[x], y_hat))\n",
    "    y = list(map(lambda x: reverse_label_index[x], y))\n",
    "    return classification_report(y, y_hat, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/luis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = evaluate(predictions, y_test, test_labels, labels_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>0.941929</td>\n",
       "      <td>0.914040</td>\n",
       "      <td>0.927775</td>\n",
       "      <td>2094.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.847310</td>\n",
       "      <td>0.822265</td>\n",
       "      <td>1264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0.884460</td>\n",
       "      <td>0.837954</td>\n",
       "      <td>0.860579</td>\n",
       "      <td>2092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>0.931936</td>\n",
       "      <td>0.973960</td>\n",
       "      <td>0.952484</td>\n",
       "      <td>3149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.993515</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.992980</td>\n",
       "      <td>42759.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.978175</td>\n",
       "      <td>0.978175</td>\n",
       "      <td>0.978175</td>\n",
       "      <td>0.978175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.650071</td>\n",
       "      <td>0.652244</td>\n",
       "      <td>0.650869</td>\n",
       "      <td>51362.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.978322</td>\n",
       "      <td>0.978175</td>\n",
       "      <td>0.978168</td>\n",
       "      <td>51362.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "B-LOC          0.000000  0.000000  0.000000      0.000000\n",
       "B-MISC         0.000000  0.000000  0.000000      4.000000\n",
       "I-LOC          0.941929  0.914040  0.927775   2094.000000\n",
       "I-MISC         0.798658  0.847310  0.822265   1264.000000\n",
       "I-ORG          0.884460  0.837954  0.860579   2092.000000\n",
       "I-PER          0.931936  0.973960  0.952484   3149.000000\n",
       "O              0.993515  0.992446  0.992980  42759.000000\n",
       "accuracy       0.978175  0.978175  0.978175      0.978175\n",
       "macro avg      0.650071  0.652244  0.650869  51362.000000\n",
       "weighted avg   0.978322  0.978175  0.978168  51362.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = [\"Texas is hot\", \"Luis lives in Lalaland\"]\n",
    "X, num_tokens = preprocessInference(ex, labels_to_index, embeddings_index)\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I-LOC', 'O', 'O'], ['I-PER', 'O', 'O', 'B-LOC']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def postProcess(predictions, num_tokens, labels_to_index):\n",
    "    reverse_label_index = {v:k for k,v in labels_to_index.items()}\n",
    "    assert len(predictions) == len(num_tokens)\n",
    "    n = len(predictions)\n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        p = preds[i][:num_tokens[i]]\n",
    "        out.append([reverse_label_index[idx] for idx in p])\n",
    "    return out     \n",
    "postProcess(predictions, num_tokens, labels_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ner_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ner_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'ner_model/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('ner_model/1/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
